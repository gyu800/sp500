{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import data form csv file \n",
    "import csv\n",
    "\n",
    "dates = []\n",
    "columnNames = []\n",
    "signal = []\n",
    "spy = []\n",
    "\n",
    "i=1\n",
    "#Cannot disclose the confidential dataset. Will prepare a testing data soon from public source\n",
    "with open('data.csv', newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',')\n",
    "    for row in spamreader:\n",
    "        if i==1: \n",
    "            i=i+1\n",
    "            columnNames = row\n",
    "            continue            \n",
    "        if row[0]: \n",
    "            dates.append(row[0])\n",
    "            signal.append(row[1])  \n",
    "            spy.append(row[2]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#convert data string to float\n",
    "import numpy as np\n",
    "numRow = len(spy)\n",
    "dataAll = np.zeros((numRow,2))\n",
    "for i in range(numRow):\n",
    "        if len(signal[i]) != 0: #empty entry has a default value of 0.00\n",
    "            dataAll[i,0] = float(signal[i])\n",
    "        if len(spy[i]) != 0: #empty entry has a default value of 0.00\n",
    "            dataAll[i,1] = float(spy[i])\n",
    "            \n",
    "#convert dates to datetime.dates\n",
    "import datetime as dt\n",
    "datesData = np.array([dt.datetime.strptime(d,'%Y%m%d').date() for d in dates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot data and check by eyes\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.figure(1)\n",
    "subfig1 = plt.subplot(211)\n",
    "plt.plot(datesData, dataAll[:,0], color='blue',linewidth=3)\n",
    "subfig1.set_title(\"Signal\")\n",
    "\n",
    "subfig2 = plt.subplot(212)\n",
    "plt.plot(datesData, dataAll[:,1], color='red', linewidth=3)\n",
    "subfig2.set_title(\"SPY\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot data and check by eyes\n",
    "plt.figure(1)\n",
    "plt.scatter(dataAll[:,0],  dataAll[:,1], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.hist(dataAll[:,0])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.hist(dataAll[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there could be outliers or error data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#identify outliers with MLE which assuming both signal and spy with normal distribution. \n",
    "#The assumption may not be sure and works well for the case.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "n_features = 2\n",
    "X = dataAll\n",
    "\n",
    "#estimators learnt from the full data set with true parameters\n",
    "emp_cov = EmpiricalCovariance().fit(X)\n",
    "\n",
    "###############################################################################\n",
    "# Display results\n",
    "fig = plt.figure()\n",
    "\n",
    "# Show data set\n",
    "subfig1 = plt.subplot(211)\n",
    "inlier_plot = subfig1.scatter(X[:, 0], X[:, 1],\n",
    "                              color='black', label='inliers')\n",
    "subfig1.set_title(\"Signal vs SPY\")\n",
    "\n",
    "# Show contours of the distance functions\n",
    "xx, yy = np.meshgrid(np.linspace(plt.xlim()[0], plt.xlim()[1], 100),\n",
    "                     np.linspace(plt.ylim()[0], plt.ylim()[1], 100))\n",
    "zz = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "mahal_emp_cov = emp_cov.mahalanobis(zz)\n",
    "mahal_emp_cov = mahal_emp_cov.reshape(xx.shape)\n",
    "emp_cov_contour = subfig1.contour(xx, yy, np.sqrt(mahal_emp_cov),\n",
    "                                  cmap=plt.cm.PuBu_r,\n",
    "                                  linestyles='dashed')\n",
    "\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "# Plot the scores for each point\n",
    "emp_mahal = emp_cov.mahalanobis(X - np.mean(X, 0)) ** (0.33)\n",
    "subfig2 = plt.subplot(212)\n",
    "bp = subfig2.boxplot(emp_mahal)\n",
    "subfig2.plot(1.26 * np.ones(numRow),\n",
    "             emp_mahal[:], '+k', markeredgewidth=1)\n",
    "\n",
    "#subfig2.axes.set_xticklabels(('inliers', 'outliers'), size=15)\n",
    "subfig2.set_ylabel(r\"$\\sqrt[3]{\\rm{(Mahal. dist.)}}$\", size=16)\n",
    "subfig2.set_title(\"1. from non-robust estimates\\n(Maximum Likelihood)\")\n",
    "plt.yticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "limit = bp[\"caps\"][1].get_data()[1][0]\n",
    "outliers = X[np.where(emp_mahal>limit)]\n",
    "outlier_plot = subfig1.scatter(outliers[:, 0], outliers[:, 1], color='red', label='outliers')\n",
    "\n",
    "subfig1.legend([emp_cov_contour.collections[1],\n",
    "                inlier_plot, outlier_plot],\n",
    "               ['MLE dist', 'inliers', 'outliers'],\n",
    "               loc=\"upper right\", borderaxespad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove outlier from dataAll\n",
    "dataNew = dataAll[np.where(emp_mahal<limit)]\n",
    "datesDataNew = datesData[np.where(emp_mahal<limit)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import numpy as np\n",
    "datesData = np.array([dt.datetime.strptime(d,'%Y%m%d').date() for d in dates])\n",
    "datesDataNew = datesData[np.where(emp_mahal<limit)]\n",
    "#plot data and check by eyes\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.figure(1)\n",
    "subfig1 = plt.subplot(211)\n",
    "plt.plot(datesDataNew, dataNew[:,0], color='blue',linewidth=3)\n",
    "subfig1.set_title(\"Signal\")\n",
    "\n",
    "subfig2 = plt.subplot(212)\n",
    "plt.plot(datesDataNew, dataNew[:,1], color='red', linewidth=3)\n",
    "\n",
    "subfig2.set_title(\"SPY\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot data and check by eyes\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(1)\n",
    "plt.scatter(dataNew[:,0],dataNew[:,1], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "more outliers may exist beased on observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#run the same algorithm and identify other outliers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.covariance import EmpiricalCovariance, MinCovDet\n",
    "\n",
    "n_features = 2\n",
    "X = dataNew\n",
    "numRow = len(X)\n",
    "\n",
    "# compare estimators learnt from the full data set with true parameters\n",
    "emp_cov = EmpiricalCovariance().fit(X)\n",
    "\n",
    "###############################################################################\n",
    "# Display results\n",
    "fig = plt.figure()\n",
    "\n",
    "# Show data set\n",
    "subfig1 = plt.subplot(211)\n",
    "inlier_plot = subfig1.scatter(X[:, 0], X[:, 1],\n",
    "                              color='black', label='inliers')\n",
    "subfig1.set_title(\"Signal vs SPY\")\n",
    "\n",
    "# Show contours of the distance functions\n",
    "xx, yy = np.meshgrid(np.linspace(plt.xlim()[0], plt.xlim()[1], 100),\n",
    "                     np.linspace(plt.ylim()[0], plt.ylim()[1], 100))\n",
    "zz = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "mahal_emp_cov = emp_cov.mahalanobis(zz)\n",
    "mahal_emp_cov = mahal_emp_cov.reshape(xx.shape)\n",
    "emp_cov_contour = subfig1.contour(xx, yy, np.sqrt(mahal_emp_cov),\n",
    "                                  cmap=plt.cm.PuBu_r,\n",
    "                                  linestyles='dashed')\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "# Plot the scores for each point\n",
    "emp_mahal = emp_cov.mahalanobis(X - np.mean(X, 0)) ** (0.33)\n",
    "subfig2 = plt.subplot(212)\n",
    "bp = subfig2.boxplot(emp_mahal)\n",
    "subfig2.plot(1.26 * np.ones(numRow),\n",
    "             emp_mahal[:], '+k', markeredgewidth=1)\n",
    "\n",
    "#subfig2.axes.set_xticklabels(('inliers', 'outliers'), size=15)\n",
    "subfig2.set_ylabel(r\"$\\sqrt[3]{\\rm{(Mahal. dist.)}}$\", size=16)\n",
    "subfig2.set_title(\"1. from non-robust estimates\\n(Maximum Likelihood)\")\n",
    "plt.yticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "limit = bp[\"caps\"][1].get_data()[1][0]\n",
    "outliers = X[np.where(emp_mahal>limit)]\n",
    "outlier_plot = subfig1.scatter(outliers[:, 0], outliers[:, 1], color='red', label='outliers')\n",
    "subfig1.legend([emp_cov_contour.collections[1],\n",
    "                inlier_plot, outlier_plot],\n",
    "               ['MLE dist', 'inliers', 'outliers'],\n",
    "               loc=\"upper right\", borderaxespad=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove more outliers\n",
    "dataNew2 = dataNew[np.where(emp_mahal<limit)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#evaluate what technique should be used\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "#datesData = np.array([dt.datetime.strptime(d,'%Y%m%d').date() for d in dates])\n",
    "datesDataNew2 = datesDataNew[np.where(emp_mahal<limit)]\n",
    "#plot data and check by eyes\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.figure(1)\n",
    "subfig1 = plt.subplot(211)\n",
    "plt.plot(datesDataNew2, dataNew2[:,0], color='blue',linewidth=3)\n",
    "subfig1.set_title(\"Signal\")\n",
    "\n",
    "subfig2 = plt.subplot(212)\n",
    "plt.plot(datesDataNew2, dataNew2[:,1], color='red', linewidth=3)\n",
    "\n",
    "subfig2.set_title(\"SPY\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot data and check by eyes\n",
    "import matplotlib.pyplot as plt\n",
    "#lag =1\n",
    "plt.figure(1)\n",
    "#plt.scatter(dataNew2[lag:,0],dataNew2[:0-lag,1], color='red')\n",
    "plt.scatter(dataNew2[:,0],dataNew2[:,1], color='red')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.hist(dataNew2[:,0])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.hist(dataNew2[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retData = np.log(dataNew2[1:,:]/dataNew2[0:-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "subfig1 = plt.subplot(211)\n",
    "plt.plot(datesDataNew2[1:], retData[:,0], color='blue',linewidth=3)\n",
    "subfig1.set_title(\"Signal\")\n",
    "\n",
    "subfig2 = plt.subplot(212)\n",
    "plt.plot(datesDataNew2[1:], retData[:,1], color='red', linewidth=3)\n",
    "\n",
    "subfig2.set_title(\"SPY\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.hist(retData[:,0])\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.hist(retData[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot data and check by eyes\n",
    "import matplotlib.pyplot as plt\n",
    "#lag =6\n",
    "plt.figure(1)\n",
    "#plt.scatter(retData[lag:,0],retData[:0-lag,1], color='red')\n",
    "plt.scatter(dataNew2[1:,0],retData[:,1], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "very good linear correlation between signal and spy and I will try linear regression first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#divide data into train and test dataset\n",
    "# proportion of training data\n",
    "p = 0.6\n",
    "split = int(len(dataNew2)*0.6)\n",
    "trainX = dataNew2[:,0][:split]\n",
    "testX = dataNew2[:,0][split:]\n",
    "trainY = dataNew2[:,1][:split]\n",
    "testY = dataNew2[:,1][split:]\n",
    "trainX =trainX.reshape(-1,1)\n",
    "testX =testX.reshape(-1,1)\n",
    "\n",
    "trainDate = datesDataNew2[:split]\n",
    "testDate = datesDataNew2[split:]\n",
    "trainDate =trainDate.reshape(-1,1)\n",
    "testDate =testDate.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 39.92454496]\n",
      "Residual sum of squares: 7.108785\n",
      "Variance score: 0.926325\n"
     ]
    }
   ],
   "source": [
    "#apply linear regression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "lm = linear_model.LinearRegression()\n",
    "# Train the model using the training sets\n",
    "lm.fit(trainX, trainY)\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', lm.coef_)\n",
    "# The mean square error\n",
    "print(\"Residual sum of squares: %.6f\"\n",
    "      % np.mean((lm.predict(testX) - testY) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.6f' % lm.score(testX, testY))\n",
    "\n",
    "# Plot outputs\n",
    "plt.figure(1)\n",
    "subfig1 = plt.subplot(211)\n",
    "subfig1.scatter(testX, testY,  color='red')\n",
    "subfig1.scatter(testX, lm.predict(testX), color='blue')\n",
    "subfig1.set_title(\"Signal\")\n",
    "\n",
    "subfig2 = plt.subplot(212)\n",
    "subfig2.plot(range(0,len(testY)), lm.predict(testX), color='blue',\n",
    "         linewidth=3)\n",
    "subfig2.plot(range(0,len(testY)), testY, color='red',\n",
    "         linewidth=3)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared is not high and out-of-sample testing is not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot residuals and \n",
    "plt.plot(range(0,len(trainY)), trainY-lm.predict(trainX), color='red',\n",
    "         linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#prepare residuals for applying pandas's time series analysis to get a hint for improving the linear model\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import qqplot\n",
    "import datetime\n",
    "resTrain = trainY-lm.predict(trainX)\n",
    "dateIndex = [datetime.datetime.combine(x[0], datetime.time.min)  for x in trainDate.tolist()]\n",
    "dta = pd.DataFrame(resTrain, index=pd.Index(dateIndex), columns=['Residual'])\n",
    "dta.plot(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check autocorrelation and partial autocorrelation of residuals\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(dta.values.squeeze(), lags=40, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(dta, lags=40, ax=ax2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on time series ananlysis, the model could be MA(3) or AR(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test MA(3) case\n",
    "trainX1 = np.roll(trainX,1)\n",
    "trainX2 = np.roll(trainX,2)\n",
    "trainX3 = np.roll(trainX,3)\n",
    "\n",
    "trainXm = np.column_stack((trainX,trainX1,trainX2,trainX3))\n",
    "trainXm = trainXm[3:,:]\n",
    "trainYm = trainY[3:]\n",
    "\n",
    "testX1 = np.roll(testX,1)\n",
    "testX2 = np.roll(testX,2)\n",
    "testX3 = np.roll(testX,3)\n",
    "\n",
    "testXm = np.column_stack((testX,testX1,testX2,testX3))\n",
    "testXm = testXm[3:,:]\n",
    "testYm = testY[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [  2.32872012   0.98432396  24.56289895  12.67977699]\n",
      "Residual sum of squares: 3.414044\n",
      "Variance score: 0.964160\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "lm = linear_model.LinearRegression()\n",
    "# Train the model using the training sets\n",
    "lm.fit(trainXm, trainYm)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', lm.coef_)\n",
    "# The mean square error\n",
    "print(\"Residual sum of squares: %.6f\"\n",
    "      % np.mean((lm.predict(testXm) - testYm) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.6f' % lm.score(testXm, testYm))\n",
    "\n",
    "# Plot outputs\n",
    "plt.figure(1)\n",
    "plt.plot(range(0,len(testYm)), lm.predict(testXm), color='blue',\n",
    "         linewidth=3)\n",
    "plt.plot(range(0,len(testYm)), testYm, color='red',\n",
    "         linewidth=3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding MA(3) does not improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test AR(3) case\n",
    "trainX1 = np.roll(trainY,1)\n",
    "trainX2 = np.roll(trainY,2)\n",
    "trainX3 = np.roll(trainY,3)\n",
    "\n",
    "trainXm = np.column_stack((trainX,trainX1,trainX2,trainX3))\n",
    "trainXm = trainXm[3:,:]\n",
    "trainYm = trainY[3:]\n",
    "\n",
    "testX1 = np.roll(testY,1)\n",
    "testX2 = np.roll(testY,2)\n",
    "testX3 = np.roll(testY,3)\n",
    "\n",
    "testXm = np.column_stack((testX,testX1,testX2,testX3))\n",
    "testXm = testXm[3:,:]\n",
    "testYm = testY[3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ 10.31966367   0.75812301   0.01361146  -0.02607735]\n",
      "Residual sum of squares: 1.338787\n",
      "Variance score: 0.985946\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create linear regression object\n",
    "lm = linear_model.LinearRegression()\n",
    "# Train the model using the training sets\n",
    "lm.fit(trainXm, trainYm)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', lm.coef_)\n",
    "# The mean square error\n",
    "print(\"Residual sum of squares: %.6f\"\n",
    "      % np.mean((lm.predict(testXm) - testYm) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.6f' % lm.score(testXm, testYm))\n",
    "\n",
    "# Plot outputs\n",
    "plt.figure(1)\n",
    "plt.plot(range(0,len(testYm)), lm.predict(testXm), color='blue',\n",
    "         linewidth=3)\n",
    "plt.plot(range(0,len(testYm)), testYm, color='red',\n",
    "         linewidth=3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AR(3) is a better model with significantly improved R2!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot residuals for AR(3)\n",
    "plt.plot(range(0,len(trainYm)), trainYm-lm.predict(trainXm), color='red',\n",
    "         linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0\n",
      "coef: [ 9.40097093  0.77805295  0.01344435 -0.0234138 ]\n",
      "Residual sum of squares: 1.315673\n",
      "Variance score: 0.986188\n"
     ]
    }
   ],
   "source": [
    "#since added three time lag terms, we tried other linear models to prevent overfitting.\n",
    "from sklearn import linear_model\n",
    "lmRidgecv = linear_model.RidgeCV(alphas=[0.1,0.5,1.0,5.0,10.0,25.0,50])\n",
    "lmRidgecv.fit(trainXm, trainYm)       \n",
    "#RidgeCV(alphas=[0.1, 1.0, 10.0], cv=None, fit_intercept=True, scoring=None,\n",
    "#    normalize=False)\n",
    "print(\"alpha: %d\" % lmRidgecv.alpha_)\n",
    "print(\"coef:\" , lmRidgecv.coef_)\n",
    "print(\"Residual sum of squares: %.6f\"\n",
    "      % np.mean((lmRidgecv.predict(testXm) - testYm) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.6f' % lmRidgecv.score(testXm, testYm))\n",
    "#plt.scatter(testX, testY,  color='black')\n",
    "plt.plot(range(len(testYm)), lmRidgecv.predict(testXm), color='blue',  linewidth=3)\n",
    "plt.plot(range(len(testYm)), testYm, color='red',   linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0\n",
      "coef: [ 9.91475281  0.76783816  0.01185739 -0.02414552]\n",
      "Residual sum of squares: 1.327455\n",
      "Variance score: 0.986064\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "clf = linear_model.LassoCV(alphas=[0.001,0.1,0.5,0.8,1.0,2.0,5.0,10.0,25.0])\n",
    "clf.fit(trainXm, trainYm) \n",
    "print(\"alpha: %d\" % clf.alpha_)\n",
    "print(\"coef:\" , clf.coef_)\n",
    "print(\"Residual sum of squares: %.6f\"\n",
    "      % np.mean((clf.predict(testXm) - testYm) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.6f' % clf.score(testXm, testYm))\n",
    "#plt.scatter(testX, testY,  color='black')\n",
    "plt.plot(range(len(testYm)), clf.predict(testXm), color='blue',  linewidth=3)\n",
    "plt.plot(range(len(testYm)), testYm, color='red',   linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0\n",
      "coef: [ 8.49903788  0.79808296  0.01240818 -0.02038617]\n",
      "Residual sum of squares: 1.299776\n",
      "Variance score: 0.986355\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import linear_model\n",
    "clf = linear_model.ElasticNetCV(alphas=[0.001,0.1,0.5,0.8,1.0,2.0,5.0,10.0,25.0])\n",
    "clf.fit(trainXm, trainYm) \n",
    "print(\"alpha: %d\" % clf.alpha_)\n",
    "print(\"coef:\" , clf.coef_)\n",
    "print(\"Residual sum of squares: %.6f\"\n",
    "      % np.mean((clf.predict(testXm) - testYm) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.6f' % clf.score(testXm, testYm))\n",
    "#plt.scatter(testX, testY,  color='black')\n",
    "plt.plot(range(len(testYm)), clf.predict(testXm), color='blue',  linewidth=3)\n",
    "plt.plot(range(len(testYm)), testYm, color='red',   linewidth=3)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All cross validaton tests lead to alpha = 0 for all three models supporting no overfitting. All models should be equally good.\n",
    "The best model I choose in terms R-square is ElasticNet\n",
    "# spy(t) = 8.499*Signal(t) + 0.7981*spy(t-1) 0.0124*spy(t-2) -0.0204*spy(t-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Double check the final model's residual\n",
    "#perform time series analysis on residuals\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.api import qqplot\n",
    "import datetime\n",
    "resTrain = trainYm-clf.predict(trainXm)\n",
    "dateIndex = [datetime.datetime.combine(x[0], datetime.time.min)  for x in trainDate.tolist()]\n",
    "dta = pd.DataFrame(resTrain, index=pd.Index(dateIndex[3:]), columns=['Residual'])\n",
    "dta.plot(figsize=(12,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(dta.values.squeeze(), lags=40, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(dta, lags=40, ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Very good!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
